{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a7c0a3-a5ed-4ede-9c9d-a89d74a1cb28",
   "metadata": {},
   "source": [
    "Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos\n",
    "\n",
    "Create a simple UI with all functionalities mentioned above and deploy it in AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d1e53-26e5-4b91-bacc-dc399d94a1f4",
   "metadata": {},
   "source": [
    "# Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e1c9081-9726-4ac3-bc7d-1ba45fe0af90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video URLs saved to video_urls.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"  \n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the elements containing video links\n",
    "video_links = soup.find_all(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Create a list to store video data\n",
    "video_data = []\n",
    "\n",
    "# Extract the video URLs and titles of the first five videos\n",
    "for i, link in enumerate(video_links[:5], start=1):\n",
    "    video_url = \"https://www.youtube.com\" + link[\"href\"]\n",
    "    video_data.append({\"Video Number\": i, \"Video URL\": video_url})\n",
    "    print(f\"Video {i}: {video_url}\")\n",
    "\n",
    "# Print video data in CSV format\n",
    "for data in video_data:\n",
    "    print(f\"{data['Video Number']},{data['Video URL']}\")\n",
    "\n",
    "# Save video data to a CSV file\n",
    "csv_filename = \"video_urls.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=[\"Video Number\", \"Video URL\"])\n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(video_data)\n",
    "\n",
    "print(f\"Video URLs saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf2da4-2c11-4767-a8d9-2428a9251bce",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "428fd64b-4899-45a1-ad56-43af1fcc3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"  \n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the elements containing video thumbnail URLs\n",
    "thumbnail_elements = soup.select(\"a.yt-simple-endpoint.style-scope.ytd-grid-video-renderer img\")\n",
    "\n",
    "# Extract and print the URLs of the video thumbnails for the first five videos\n",
    "for i, thumbnail in enumerate(thumbnail_elements[:5], start=1):\n",
    "    thumbnail_url = thumbnail[\"src\"]\n",
    "    print(f\"Thumbnail for Video {i}: {thumbnail_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588f83f-9115-43e3-bde2-ecc93de3b9a4",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd161007-24c5-499e-986e-69110cc4a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"  \n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the elements containing video titles\n",
    "title_elements = soup.select(\"a#video-title\")\n",
    "\n",
    "# Extract and print the titles of the first five videos\n",
    "for i, title_element in enumerate(title_elements[:5], start=1):\n",
    "    title = title_element.get(\"title\")\n",
    "    print(f\"Title of Video {i}: {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c690f9-9111-4d97-bcc8-03066a95c2db",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "334ecc09-5d95-4f54-bef3-89e7fafd646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"  \n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the elements containing video view counts\n",
    "view_count_elements = soup.select(\"span.style-scope.ytd-grid-video-renderer span.ytd-grid-video-renderer:nth-of-type(2)\")\n",
    "\n",
    "# Extract and print the view counts of the first five videos\n",
    "for i, view_count_element in enumerate(view_count_elements[:5], start=1):\n",
    "    view_count = view_count_element.get_text()\n",
    "    print(f\"View count of Video {i}: {view_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea9b85-37c0-4993-b1a9-577174a2a277",
   "metadata": {},
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d179092-5b68-49ba-a9d4-d1ed153dc509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"  \n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the elements containing video posting times\n",
    "time_elements = soup.select(\"span.style-scope.ytd-grid-video-renderer div.style-scope.ytd-thumbnail-overlay-time-status-renderer\")\n",
    "\n",
    "# Extract and print the posting times of the first five videos\n",
    "for i, time_element in enumerate(time_elements[:5], start=1):\n",
    "    posting_time = time_element.get_text().strip()\n",
    "    print(f\"Posting time of Video {i}: {posting_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed668d-69ce-4728-b82f-e5fb805f2d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
